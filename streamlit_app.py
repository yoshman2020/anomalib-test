import csv
import io
import re
import shutil
import zipfile
from pathlib import Path

import cv2
import numpy as np
import pandas as pd
import streamlit as st
import torch
from anomalib.data.datamodules import Folder
from anomalib.data.utils import ValSplitMode
from anomalib.engine.engine import Engine
from PIL import Image
from streamlit.runtime.uploaded_file_manager import UploadedFile

import constants
import models

st.set_page_config(
    page_title="ç•°å¸¸æ¤œçŸ¥",
    page_icon=":control_knobs:",
    layout="wide",
)

train_images_placeholder = st.empty()
result_images_placeholder = st.empty()


def configure_sidebar() -> bool:
    """
    Configures the Streamlit sidebar UI for anomaly detection settings.

    The sidebar includes:
        - File uploaders for training and test images.
        - Selectboxes for choosing the anomaly detection model and its backbone.
        - Checkbox and number input for threshold configuration (with auto/manual option).
        - Number inputs for image resizing and training epochs.
        - Submit button to start the inspection process.
        - Buttons and dialogs providing information about available models and backbones.

    Returns:
        bool: True if the form is submitted ("æ¤œæŸ»é–‹å§‹" button pressed), otherwise False.
    """
    with st.sidebar:
        st.markdown("# ç•°å¸¸æ¤œçŸ¥")
        with st.form("form"):
            st.markdown("## :level_slider: æ¤œæŸ»æ¡ä»¶")

            train_images = st.file_uploader(
                "å­¦ç¿’ç”»åƒ",
                type=["png", "jpg", "jpeg", "bmp"],
                accept_multiple_files=True,
                key="train_images",
                help="å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹æ­£å¸¸ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
            )

            test_images = st.file_uploader(
                "æ¤œæŸ»ç”»åƒ",
                type=["png", "jpg", "jpeg", "bmp"],
                accept_multiple_files=True,
                key="test_images",
                help="æ¤œæŸ»ã™ã‚‹ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
            )

            model_name = st.selectbox(
                "æ¤œæŸ»æ‰‹æ³•",
                options=constants.MODEL_NAMES,
                index=12,
                key="model_name",
            )

            backbone = st.selectbox(
                "ãƒ¢ãƒ‡ãƒ«",
                options=constants.MODEL_BACKBONES[model_name],
                index=0,
                key="backbone",
            )

            threshold_auto = st.checkbox(
                "è‡ªå‹•ã—ãã„å€¤", key="threshold_auto", value=True
            )
            threshold = st.number_input(
                "ã—ãã„å€¤",
                format="%0.5f",
                key="threshold",
            )

            image_size = st.number_input(
                "ç¸®å°ã‚µã‚¤ã‚º", value=128, min_value=2, key="image_size"
            )
            epochs = st.number_input(
                "å­¦ç¿’å›æ•°", value=1, min_value=1, key="epochs"
            )

            submitted = st.form_submit_button(
                "æ¤œæŸ»é–‹å§‹",
                type="primary",
                use_container_width=True,
            )

        @st.dialog("æ¤œæŸ»æ‰‹æ³•ã«ã¤ã„ã¦", width="large")
        def about_model_name():
            df = pd.DataFrame(constants.ABOUT_MODEL_NAMES)
            st.table(df)

        if st.button("æ¤œæŸ»æ‰‹æ³•ã«ã¤ã„ã¦"):
            about_model_name()

        @st.dialog("ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦", width="large")
        def about_backbone():
            df = pd.DataFrame(constants.ABOUT_BACKBONE)
            st.table(df)

        if st.button("ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦"):
            about_backbone()

    return submitted


def disp_train_images(images: list[UploadedFile]) -> None:
    """Display the training images in a grid.

    Args:
        images (list[UploadedFile]): List of uploaded training images.
    """
    if images:
        with train_images_placeholder.container(height=300):
            st.header("å­¦ç¿’ç”»åƒ")
            # Create a grid of images
            cols = st.columns(3)
            for i, image in enumerate(images):
                cols[i % 3].image(
                    image, caption=f"{image.name}", use_container_width=True
                )


def predict_to_image(pred_image: torch.Tensor):
    """
    Converts a PyTorch tensor representing an image prediction to a NumPy uint8 image array.
    The function permutes the tensor dimensions from (C, H, W) to (W, H, C), clips the values to the [0, 1] range,
    scales them to [0, 255], and converts the result to uint8 format suitable for image display or saving.
    Args:
        pred_image (torch.Tensor): The predicted image tensor with shape (C, H, W).
    Returns:
        np.ndarray: The processed image as a NumPy array with dtype uint8 and shape (W, H, C).
    """
    return (pred_image.permute(1, 2, 0).numpy().clip(0.0, 1.0) * 255).astype(
        np.uint8
    )


def disp_result_images(predictions, threshold) -> None:
    """
    Displays the result images, anomaly maps, and prediction scores in a Streamlit app, and provides a downloadable ZIP file containing the results.

    Args:
        predictions (list): A list of prediction objects, each containing image data, anomaly maps, prediction scores, and image paths.
        threshold (float): The threshold value used to determine if a prediction is normal or anomalous.

    Functionality:
        - Displays original images, their corresponding anomaly heatmaps, and prediction results in a 3-column grid layout.
        - Generates a CSV file summarizing the results (file name, score, and judgment).
        - Packages the heatmap images and CSV file into a ZIP archive.
        - Provides a download button for the ZIP file in the Streamlit interface.

    Notes:
        - Assumes the existence of several helper functions and variables (e.g., get_map_min_max, get_item, predict_to_image, superimpose_anomaly_map_g, result_images_placeholder, constants.RESULT_PATH).
        - Handles both torch.Tensor and non-tensor image types.
        - Skips predictions with missing or invalid data.
    """
    if predictions is None:
        return
    map_min, map_max, map_ptp = get_map_min_max(predictions)
    with result_images_placeholder.container(height=300):
        st.header("æ¤œæŸ»çµæœ")
        st.info(f"ã—ãã„å€¤: {threshold:.5f}")

        # Create a grid of images
        cols = st.columns(3)

        # CSVç”¨ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‚’ç”¨æ„
        csv_buffer = io.StringIO()
        csv_writer = csv.writer(csv_buffer)
        csv_writer.writerow(
            [
                "æ¤œæŸ»æ‰‹æ³•",
                st.session_state["model_name"],
                "ãƒ¢ãƒ‡ãƒ«",
                st.session_state["backbone"],
                "ã—ãã„å€¤",
                threshold,
            ]
        )
        csv_writer.writerow(["ãƒ•ã‚¡ã‚¤ãƒ«å", "ã‚¹ã‚³ã‚¢", "åˆ¤å®š"])

        # ç”»åƒã¨csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’zipã«
        zip_path = Path(constants.RESULT_PATH) / "result.zip"
        with zipfile.ZipFile(zip_path, "w") as zipf:
            for i, prediction in enumerate(predictions):
                tile_0 = cols[0].container(height=200, border=False)
                image = get_item(prediction, "image")
                if isinstance(image, torch.Tensor):
                    np_image = predict_to_image(image)
                else:
                    continue

                pil_image = Image.fromarray(np_image)
                wh_ratio = st.session_state["test_wh_ratios"][i]
                resized_image = pil_image.resize(
                    (pil_image.width, int(pil_image.width / wh_ratio))
                )
                with tile_0:
                    st.image(resized_image, use_container_width=True)

                image_path = Path(prediction.image_path[0]).name
                image_path = re.sub(r"test_\d+\.", "", image_path)

                tile_1 = cols[1].container(height=200, border=False)
                anomaly_map = get_item(prediction, "anomaly_map")
                if anomaly_map is not None:
                    anomaly_map = anomaly_map.cpu().numpy().squeeze()  # type: ignore
                    heat_map = superimpose_anomaly_map_g(
                        anomaly_map=anomaly_map,
                        image=np_image,
                        map_min=map_min,
                        map_ptp=map_ptp,
                    )
                    pil_heat_map = Image.fromarray(heat_map)
                    resized_heat_map = pil_heat_map.resize(
                        (pil_heat_map.width, int(pil_heat_map.width / wh_ratio))
                    )
                    with tile_1:
                        st.image(resized_heat_map, use_container_width=True)

                    # zipã«æ›¸ãè¾¼ã¿
                    # ãƒ¡ãƒ¢ãƒªä¸Šã«ç”»åƒã‚’ä¿å­˜
                    img_bytes = io.BytesIO()
                    resized_heat_map.save(
                        img_bytes,
                        format="JPEG",
                    )
                    img_bytes.seek(0)

                    # ZIPã«ç”»åƒã‚’æ›¸ãè¾¼ã¿
                    zipf.writestr(
                        "result_" + Path(image_path).stem + ".jpg",
                        img_bytes.read(),
                    )

                tile_2 = cols[2].container(height=200, border=False)
                tile_2.write(f"{image_path}")
                pred_score = get_item(prediction, "pred_score")
                pred_score = pred_score if pred_score is not None else 0.0
                with tile_2:
                    if pred_score <= threshold:
                        judge = "æ­£å¸¸"
                        st.success(f"score:{pred_score:.2f} [æ­£å¸¸]")
                    else:
                        judge = "ç•°å¸¸"
                        st.error(f"score:{pred_score:.2f} [ç•°å¸¸]")

                # CSVã«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿½åŠ 
                csv_writer.writerow([image_path, pred_score, judge])

            # CSVã‚’ZIPã«è¿½åŠ 
            csv_buffer.seek(0)
            zipf.writestr(
                "result.csv", csv_buffer.getvalue().encode("utf-8-sig")
            )

        # ä¿å­˜ãƒœã‚¿ãƒ³
        st.download_button(
            "çµæœä¿å­˜",
            data=zip_path.read_bytes(),
            file_name="result.zip",
            on_click="ignore",
        )


def save_images(train_images, test_images):
    """Delete existing dataset and save images to train/test directories.

    Args:
        train_images: List of uploaded training images
        test_images: List of uploaded test images
    """

    # 1. Delete DATASET_PATH images
    dataset_path = Path(constants.DATASET_PATH)
    if dataset_path.exists():
        shutil.rmtree(dataset_path)
    result_path = Path(constants.RESULT_PATH)
    if result_path.exists():
        shutil.rmtree(result_path)

    # 2. Save train_images to DATASET_PATH/train
    train_dir = dataset_path / "train"
    train_dir.mkdir(parents=True, exist_ok=True)
    for i, image in enumerate(train_images):
        with open(train_dir / f"train_{i}.{image.name}", "wb") as f:
            f.write(image.getvalue())

    # 3. Save test_images to DATASET_PATH/test
    test_dir = dataset_path / "test"
    test_dir.mkdir(parents=True, exist_ok=True)
    # ç”»åƒç¸¦æ¨ªæ¯”
    st.session_state.test_wh_ratios = []
    for i, image in enumerate(test_images):
        with open(test_dir / f"test_{i}.{image.name}", "wb") as f:
            f.write(image.getvalue())

        pil_image = Image.open(image)
        arr = np.array(pil_image)
        h, w = arr.shape[:2]
        st.session_state.test_wh_ratios.append(w / h)


def get_item(prediction, key):
    """
    Retrieve the value associated with a given key from a prediction object, handling various data types.
    Parameters:
        prediction (object): The object containing the attribute to retrieve.
        key (str): The attribute name to access within the prediction object.
    Returns:
        The first element or scalar value associated with the specified key, depending on the type:
            - For lists or tuples: returns the first element if available, else None.
            - For torch.Tensor: returns None if empty, the scalar value if single element, or the first element otherwise.
            - For numpy.ndarray: returns None if empty, the scalar value if single element, or the first element otherwise.
            - For other types (int, float, etc.): returns the value directly.
        Returns None if the attribute does not exist.
    """
    if not hasattr(prediction, key):
        return None

    val = getattr(prediction, key)

    # list or tuple
    if isinstance(val, (list, tuple)):
        return val[0] if len(val) > 0 else None

    # PyTorch Tensor
    if isinstance(val, torch.Tensor):
        if val.numel() == 0:
            return None
        if val.numel() == 1:
            return val.item()
        return val[0] if val.dim() > 0 else val.item()

    # NumPy ndarray
    if isinstance(val, np.ndarray):
        if val.size == 0:
            return None
        if val.size == 1:
            return val.item()
        return val.flat[0]  # flat iteratorã§æœ€åˆã®è¦ç´ 

    # ãã‚Œä»¥å¤–ï¼ˆint, float, etc.ï¼‰
    return val


def get_map_min_max(predictions) -> tuple[float, float, float]:
    """
    Calculates the minimum, maximum, and range (peak-to-peak) values across anomaly maps in a list of predictions.
    Args:
        predictions (Iterable): A list or iterable of prediction objects, each containing an 'anomaly_map' attribute.
            Each 'anomaly_map' is expected to be a tensor-like object where the first element (index 0) can be
            converted to a NumPy array via `.cpu().numpy()`.
    Returns:
        tuple[float, float, float]: A tuple containing:
            - map_min (float): The minimum value found across all anomaly maps.
            - map_max (float): The maximum value found across all anomaly maps.
            - map_ptp (float): The range (max - min) of the anomaly map values.
    """
    map_min = min(
        prediction.anomaly_map[0].min().cpu().numpy()
        for prediction in predictions
    )
    map_max = max(
        prediction.anomaly_map[0].max().cpu().numpy()
        for prediction in predictions
    )
    map_ptp = map_max - map_min
    return map_min, map_max, map_ptp


def superimpose_anomaly_map_g(
    anomaly_map: np.ndarray,
    image: np.ndarray,
    map_min: float,
    map_ptp: float,
    alpha: float = 0.4,
    gamma: int = 0,
) -> np.ndarray:
    """Superimpose anomaly map on image.

    Args:
        anomaly_map (np.ndarray): Anomaly map.
        image (np.ndarray): Image.
        alpha (float): Alpha value for superimposition.
        gamma (int): Gamma value for superimposition.
        map_min (float): Minimum value of the anomaly map.
        map_ptp (float): Range of the anomaly map.

    Returns:
        np.ndarray: Superimposed image.
    """
    assert anomaly_map.shape == image.shape[:2], (
        f"Anomaly map shape {anomaly_map.shape} does not match image shape "
        f"{image.shape[:2]}."
    )
    nomalized_map = (((anomaly_map - map_min) / map_ptp) * 255).astype(np.uint8)
    color_map = cv2.applyColorMap(nomalized_map, cv2.COLORMAP_JET)
    rgb_color_map = cv2.cvtColor(color_map, cv2.COLOR_BGR2RGB)
    height, width = rgb_color_map.shape[:2]
    image = cv2.resize(image, (width, height))
    return cv2.addWeighted(rgb_color_map, alpha, image, (1 - alpha), gamma)


def main_page(submitted: bool) -> None:
    """Main page layout and logic for generating images.

    Args:
        submitted (bool): Flag indicating whether the form has been submitted.
    """

    if submitted == True:
        with st.status("å‡¦ç†ä¸­...", expanded=True) as status:

            if (
                st.session_state["train_images"] is None
                or len(st.session_state["train_images"]) == 0
            ):
                st.error("å­¦ç¿’ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                return
            if (
                st.session_state["test_images"] is None
                or len(st.session_state["test_images"]) == 0
            ):
                st.error("æ¤œæŸ»ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                return
            try:
                # Load the selected model
                model = models.get_model(
                    model_name=st.session_state["model_name"],
                    backbone=st.session_state["backbone"],
                    image_size=st.session_state["image_size"],
                )

                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
                save_images(
                    st.session_state["train_images"],
                    st.session_state["test_images"],
                )

                datamodule = Folder(
                    name="custom",
                    root=constants.DATASET_PATH,
                    normal_dir="train",
                    normal_test_dir="test",
                    val_split_mode=ValSplitMode.FROM_TRAIN,
                    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹ã¨ã‚¹ã‚³ã‚¢ãŒ1ã‹0ã«ãªã‚‹ãŸã‚ã€æ¤œè¨¼ã¯ã—ãªã„
                    # ratioã‚’0ã«ã™ã‚‹ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆ†å‰²ã•ã‚Œã‚‹ãŸã‚ã€éå¸¸ã«å°ã•ã„å€¤ã‚’è¨­å®š
                    val_split_ratio=0.0001,
                    train_batch_size=constants.BATCH_SIZE,
                    eval_batch_size=constants.BATCH_SIZE,
                    num_workers=1,
                )
                datamodule.setup()

                # ----- å­¦ç¿’ -----
                engine = Engine(
                    # callbacks=callbacks,
                    max_epochs=st.session_state["epochs"],
                    accelerator="auto",
                    devices=1,
                )
                engine.fit(
                    model=model,
                    datamodule=datamodule,
                )

                # ã—ãã„å€¤
                if st.session_state["threshold_auto"]:
                    try:
                        # trainãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢
                        train_predictions = engine.predict(
                            model=model,
                            dataloaders=datamodule.train_dataloader(),
                        )
                        train_scores = [
                            get_item(prediction, "pred_score")
                            for prediction in (train_predictions or [])
                        ]
                        # é–¾å€¤ï¼ˆ99.7ï¼…ï¼‰
                        threshold = np.mean(train_scores) + 3 * np.std(train_scores)  # type: ignore
                        # # å››åˆ†ä½ç¯„å›²Ã—1.5ã®å ´åˆ
                        # threshold = np.percentile(train_scores, 75) + 1.5 * (
                        #     np.percentile(train_scores, 75) - np.percentile(train_scores, 25)
                        # )
                    except Exception as e:
                        print(f"exception: {e}")
                        threshold = 0
                    print(f"threshold: {threshold}")
                else:
                    threshold = st.session_state["threshold"]

                # äºˆæƒ³
                predictions = engine.predict(model=model, datamodule=datamodule)

                # çµæœæç”»
                disp_train_images(st.session_state["train_images"])
                disp_result_images(predictions, threshold=threshold)

                status.update(
                    label="å‡¦ç†å®Œäº†",
                    state="complete",
                    expanded=False,
                )
            except Exception as e:
                print(e)
                st.error(f"Encountered an error: {e}", icon="ğŸš¨")

    # If not submitted, chill here ğŸ¹
    else:
        pass


def main():
    """
    Main function to run the Streamlit application.

    This function initializes the sidebar configuration and the main page layout.
    It retrieves the user inputs from the sidebar, and passes them to the main page function.
    The main page function then generates images based on these inputs.
    """
    submitted = configure_sidebar()
    main_page(submitted)


if __name__ == "__main__":
    main()
