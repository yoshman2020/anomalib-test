{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from anomalib import TaskType\n",
    "from anomalib.data.datamodules import Folder\n",
    "from anomalib.data.datasets import FolderDataset\n",
    "from anomalib.data.utils import ValSplitMode\n",
    "from anomalib.engine.engine import Engine\n",
    "from anomalib.loggers import AnomalibCometLogger\n",
    "from anomalib.models import (\n",
    "    Cfa,\n",
    "    Cflow,\n",
    "    Csflow,\n",
    "    Dfkde,\n",
    "    Dfm,\n",
    "    Draem,\n",
    "    Dsr,\n",
    "    EfficientAd,\n",
    "    Fastflow,\n",
    "    Fre,\n",
    "    Ganomaly,\n",
    "    Padim,\n",
    "    Patchcore,\n",
    "    ReverseDistillation,\n",
    "    Stfpm,\n",
    "    Supersimplenet,\n",
    "    Uflow,\n",
    "    VlmAd,\n",
    "    WinClip,\n",
    ")\n",
    "from anomalib.models.components.base import AnomalibModule\n",
    "from anomalib.models.components.classification import FeatureScalingMethod\n",
    "from anomalib.models.image.efficient_ad.torch_model import EfficientAdModelSize\n",
    "from anomalib.models.image.reverse_distillation.anomaly_map import (\n",
    "    AnomalyMapGenerationMode,\n",
    ")\n",
    "from anomalib.models.image.vlm_ad.utils import ModelName\n",
    "from anomalib.pre_processing import PreProcessor\n",
    "from anomalib.utils.post_processing import (\n",
    "    anomaly_map_to_color_map,\n",
    "    superimpose_anomaly_map,\n",
    ")\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms.v2 import Compose, Resize, ToTensor\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = [\n",
    "    # 0 # △一般に高速（データ規模依存） # 観測変数の因子構造を検証する統計的手法(Continuous Flow Analysis)\n",
    "    # SUPPORTED_BACKBONES = (\"vgg19_bn\", \"resnet18\", \"wide_resnet50_2\", \"efficientnet_b5\")\n",
    "    \"CFA\",\n",
    "    # 1 # △アプローチ・条件で異なる # 連続確率を用いて離散生成モデルを拡張するフローマッチング手法(Conditional Flow Matching)\n",
    "    \"C-Flow\",\n",
    "    # 2 # △アプローチ・条件で異なる # 連続状態離散フローマッチングモデル(Continuous-State Flow Matching)\n",
    "    # backboneなし\n",
    "    \"CS-Flow\",\n",
    "    # 3 # △大規模データ場合は処理時間が伸びる # 高次元データの外れ値検知向けのカーネル密度推定モデル(Distribution-Free Kernel Density Estimation)\n",
    "    \"DFKDE\",\n",
    "    # 4 # ×時間がかかる # 生成的フローマッチング(Deep Feature Matching)型モデル(Deep Flow Matching)\n",
    "    \"DFM\",\n",
    "    # 5 # ×時間がかかる # 深層自己監督と再構成で異常検知を行うモデル(Dual Reconstruction AutoEncoder-based Model)\n",
    "    # backboneなし\n",
    "    \"DRAEM\",\n",
    "    # 6 # ◯比較的高速 # 正規化フローを用いて外れ値を検知するモデル(Deep Subspace Reconstruction)\n",
    "    # backboneなし\n",
    "    \"DSR\",\n",
    "    # 7 # ◎非常に高速 # 計算効率重視の異常検知アルゴリズム(Efficient Anomaly Detection)\n",
    "    # backboneなし\n",
    "    \"Efficient AD\",\n",
    "    # 8 # ◯GPU推論で高速 # 高速流ベース生成による異常検知法\n",
    "    # SUPPORTED_BACKBONES = (\"cait_m48_448\", \"deit_base_distilled_patch16_384\", \"resnet18\", \"wide_resnet50_2\")\n",
    "    \"FastFlow\",\n",
    "    # 9 # ◎高速 # 再構成誤差に基づく異常検知ネットワーク(Feature Reconstruction Error)\n",
    "    \"FRE\",\n",
    "    # 10 # ×時間がかかる # 生成対向ネットワーク(GAN)による再構成誤差を活用する異常検知モデル(Generative Adversarial Network Anomaly Detection)\n",
    "    # backboneなし\n",
    "    \"GANomaly\",\n",
    "    # 11 # △構造や実装でばらつきあり # 多変量分布で特徴空間の異常を検出するモデル(Patch Distribution Modeling)\n",
    "    \"PaDiM\",\n",
    "    # 12 # ◎非常に高速 # 高次元特徴空間におけるパッチベースの異常検知モデル\n",
    "    \"PatchCore\",\n",
    "    # 13 # ◯高速 # 教師あり逆蒸留法を用いた異常検知モデル\n",
    "    \"Reverse Distillation\",\n",
    "    # 14 # △構造や実装でばらつきあり # 教師なし空間的注意機構(フローベースパッチマッチング)を用いた異常検知モデル(Student-Teacher Feature Pyramid Matching)\n",
    "    \"STFPM\",\n",
    "    # 15 # ◎非常に高速 # シンプルで効果的な異常検知ニューラルネットワーク\n",
    "    \"SuperSimpleNet\",\n",
    "    # 16 # △アプローチ・条件で異なる # 光フロー(U-Net構造)を用いた異常検知モデル(U-Net-based Flow)\n",
    "    # AVAILABLE_EXTRACTORS = [\"mcait\", \"resnet18\", \"wide_resnet50_2\"]\n",
    "    \"U-Flow\",\n",
    "    # 17 # △推論時間長め # 大規模視覚言語モデルを用いた異常検知モデル(Vision-Language Model for Anomaly Detection)\n",
    "    # backboneなし\n",
    "    \"VLM-AD\",\n",
    "    # 18 # △推論時間長め # ウィンドウ注意機構を用いたCLIPベースの異常検知モデル(Windowed CLIP)\n",
    "    # backboneなし\n",
    "    \"WinCLIP\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONES = [\n",
    "    # ResNet 一般的なモデル\n",
    "    # 0 # ◎非常に高速\n",
    "    \"resnet18\",\n",
    "    # 1 # ◯高速\n",
    "    \"resnet50\",\n",
    "    # 2 # △やや遅い\n",
    "    \"resnet101\",\n",
    "    # 3 # ×遅め\n",
    "    \"resnet152\",\n",
    "    # Wide ResNet より広い層を持つモデル\n",
    "    # 4 # ◯高速\n",
    "    \"wide_resnet50_2\",\n",
    "    # 5 # △やや遅い\n",
    "    \"wide_resnet101_2\",\n",
    "    # EfficientNet 軽量で高性能なモデル\n",
    "    # 6 # ◎非常に高速\n",
    "    \"efficientnet_b0\",\n",
    "    # 7 # ◯高速\n",
    "    \"efficientnet_b3\",\n",
    "    # 8 # △やや遅め\n",
    "    \"efficientnet_b4\",\n",
    "    # 9 # △やや遅め\n",
    "    \"efficientnet_b5\",\n",
    "    # Vision Transformer (ViT) 画像のパッチを特徴量として取り込むモデル\n",
    "    # 10 # △やや遅い\n",
    "    \"vit_base_patch16_224\",\n",
    "    # 11 # ×遅め\n",
    "    \"vit_large_patch16_224\",\n",
    "    # Swin Transformer 局所的な注意機構を持つモデル\n",
    "    # 13 # △やや遅い\n",
    "    \"swin_base_patch4_window7_224\",\n",
    "    # 14 # ×遅め\n",
    "    \"swin_large_patch4_window7_224\",\n",
    "    # DenseNet 高密度な接続を持つモデル\n",
    "    # 15 # ◯高速\n",
    "    \"densenet121\",\n",
    "    # 16 # ◯高速\n",
    "    \"densenet169\",\n",
    "    # 17 # △やや遅い\n",
    "    \"densenet201\",\n",
    "    # RegNet 効率的なアーキテクチャを持つモデル\n",
    "    # 18 # ◎非常に高速\n",
    "    \"regnetx_002\",\n",
    "    # 19 # ◯高速\n",
    "    \"regnetx_004\",\n",
    "    # 20 # ◎非常に高速\n",
    "    \"regnety_032\",\n",
    "    # MobileNet 軽量なモデル\n",
    "    # 21 # ◎非常に高速\n",
    "    \"mobilenetv2_100\",\n",
    "    # 22 # ◎非常に高速\n",
    "    \"mobilenetv3_large_100\",\n",
    "    # VGG シンプルで広く使われるモデル\n",
    "    # 23 # △やや遅い\n",
    "    \"vgg19_bn\",\n",
    "    # ViT派生の大規模モデルで、大規模データセット向き(Class-Attention in Image Transformers)\n",
    "    # 24 # ×時間がかかる\n",
    "    \"cait_m48_448\",\n",
    "    # 蒸留で軽量・効率化したViTモデル(Data-efficient Image Transformer Base Distilled Patch)\n",
    "    # 25 # ×時間がかかる\n",
    "    \"deit_base_distilled_patch16_384\",\n",
    "    # マルチヘッド層と階層的注意機構で視覚タスクに高精度をもたらすVision Transformerモデル\n",
    "    # 26 # △やや遅い\n",
    "    \"mcait\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be443ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 設定 -----\n",
    "DATASET_PATH = \"./datasets/custom\"\n",
    "DATASET_PATH_ANOMALY = \"./datasets/custom_anomaly\"\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "CHECKPOINT_PATH = \"./checkpoint.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be175da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"CFA\"\n",
    "# MODEL_NAME = \"C-Flow\"\n",
    "# MODEL_NAME = \"CS-Flow\"\n",
    "# MODEL_NAME = \"DFKDE\"\n",
    "# MODEL_NAME = \"DFM\"\n",
    "# MODEL_NAME = \"DRAEM\"\n",
    "# MODEL_NAME = \"DSR\"\n",
    "# MODEL_NAME = \"Efficient AD\"\n",
    "# MODEL_NAME = \"FastFlow\"\n",
    "# MODEL_NAME = \"FRE\"\n",
    "# MODEL_NAME = \"GANomaly\"\n",
    "# MODEL_NAME = \"PaDiM\"\n",
    "# MODEL_NAME = \"PatchCore\"\n",
    "# MODEL_NAME = \"Reverse Distillation\"\n",
    "# MODEL_NAME = \"STFPM\"\n",
    "# TODO\n",
    "# MODEL_NAME = \"SuperSimpleNet\"\n",
    "# MODEL_NAME = \"U-Flow\"\n",
    "# MODEL_NAME = \"VLM-AD\"\n",
    "MODEL_NAME = \"WinCLIP\"\n",
    "# BACKBONE = \"\"\n",
    "# BACKBONE = \"resnet18\"\n",
    "# BACKBONE = \"resnet50\"\n",
    "# BACKBONE = \"efficientnet_b0\"\n",
    "BACKBONE = \"wide_resnet50_2\"\n",
    "# BACKBONE = \"mcait\"\n",
    "\n",
    "# バックボーンから特徴抽出層を取得\n",
    "if BACKBONE in [\"\", \"mcait\"]:\n",
    "    layers = []\n",
    "else:\n",
    "    feature_model = timm.create_model(BACKBONE, features_only=True)\n",
    "    layers = feature_model.feature_info.module_name() # type: ignore\n",
    "    print(layers)\n",
    "\n",
    "# 前処理の設定\n",
    "transform = Compose([Resize((IMAGE_SIZE, IMAGE_SIZE))])\n",
    "pre_processor = PreProcessor(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2190e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- モデル構築 -----\n",
    "if MODEL_NAME == \"CFA\":\n",
    "    model = Cfa(\n",
    "        backbone=BACKBONE,\n",
    "        pre_processor=pre_processor,\n",
    "        visualizer=False,\n",
    "        gamma_c=1,\n",
    "        gamma_d=1,\n",
    "        num_nearest_neighbors=3,\n",
    "        num_hard_negative_features=3,\n",
    "        radius=1e-5,\n",
    "    )\n",
    "    # max_epochs = 30\n",
    "    # callbacks = [EarlyStopping(patience=5, monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"C-Flow\":\n",
    "    model = Cflow(\n",
    "        backbone=BACKBONE,\n",
    "        pre_processor=pre_processor,\n",
    "        layers=layers[-3:],\n",
    "        fiber_batch_size=BATCH_SIZE,\n",
    "        pre_trained=True,\n",
    "        decoder=\"freia-cflow\",\n",
    "        condition_vector=128,\n",
    "        coupling_blocks=8,\n",
    "        clamp_alpha=1.9,\n",
    "        permute_soft=False,\n",
    "        lr=0.0001,\n",
    "    )\n",
    "    # max_epochs = 50\n",
    "    # callbacks = [EarlyStopping(patience=5, monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"CS-Flow\":\n",
    "    model = Csflow(\n",
    "        pre_processor=pre_processor,\n",
    "        cross_conv_hidden_channels=1024,\n",
    "        n_coupling_blocks=4,\n",
    "        clamp=3,\n",
    "        num_channels=3,\n",
    "    )\n",
    "    # max_epochs = 240\n",
    "elif MODEL_NAME == \"DFKDE\":\n",
    "    model = Dfkde(\n",
    "        backbone=BACKBONE,\n",
    "        layers=[layers[-1]],\n",
    "        # pre_processor = pre_processor,\n",
    "        pre_trained=True,\n",
    "        # n_pca_components=16,\n",
    "        n_pca_components=1,\n",
    "        feature_scaling_method=FeatureScalingMethod.SCALE,\n",
    "        max_training_points=40000,\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "    # callbacks = [EarlyStopping(monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"DFM\":\n",
    "    model = Dfm(\n",
    "        backbone=BACKBONE,\n",
    "        layer=layers[-2],\n",
    "        pre_processor=pre_processor,\n",
    "        pre_trained=True,\n",
    "        pooling_kernel_size=4,\n",
    "        pca_level=0.97,\n",
    "        score_type=\"fre\",\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "elif MODEL_NAME == \"DRAEM\":\n",
    "    model = Draem(\n",
    "        pre_processor=pre_processor,\n",
    "        enable_sspcab=False,\n",
    "        sspcab_lambda=0.1,\n",
    "        anomaly_source_path=None,\n",
    "        beta=(0.1, 1.0),\n",
    "    )\n",
    "    # max_epochs = 700\n",
    "    # callbacks = [EarlyStopping(patience=20, monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"DSR\":\n",
    "    model = Dsr(\n",
    "        pre_processor=pre_processor,\n",
    "        latent_anomaly_strength=0.2,\n",
    "        upsampling_train_ratio=0.7,\n",
    "    )\n",
    "    # max_epochs = 700\n",
    "elif MODEL_NAME == \"Efficient AD\":\n",
    "    model = EfficientAd(\n",
    "        pre_processor=pre_processor,\n",
    "        imagenet_dir=\"./datasets/imagenette\",\n",
    "        teacher_out_channels=384,\n",
    "        model_size=EfficientAdModelSize.S,\n",
    "        lr=0.0001,\n",
    "        weight_decay=0.00001,\n",
    "        padding=False,\n",
    "        pad_maps=True,\n",
    "    )\n",
    "    # max_epochs = 1000\n",
    "elif MODEL_NAME == \"FastFlow\":\n",
    "    model = Fastflow(\n",
    "        backbone=BACKBONE,\n",
    "        pre_processor=pre_processor,\n",
    "        pre_trained=True,\n",
    "        flow_steps=8,\n",
    "        conv3x3_only=False,\n",
    "        hidden_ratio=1.0,\n",
    "    )\n",
    "    # max_epochs = 500\n",
    "    # callbacks = [EarlyStopping(monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"FRE\":\n",
    "    model = Fre(\n",
    "        backbone=BACKBONE,\n",
    "        layer=layers[-2],\n",
    "        pre_processor=pre_processor,\n",
    "        input_dim=IMAGE_SIZE * IMAGE_SIZE,\n",
    "        latent_dim=IMAGE_SIZE,\n",
    "        pre_trained=True,\n",
    "        pooling_kernel_size=2,\n",
    "    )\n",
    "    # max_epochs = 1220\n",
    "elif MODEL_NAME == \"GANomaly\":\n",
    "    model = Ganomaly(\n",
    "        pre_processor=pre_processor,\n",
    "        batch_size=32,\n",
    "        n_features=64,\n",
    "        latent_vec_size=100,\n",
    "        extra_layers=0,\n",
    "        add_final_conv_layer=True,\n",
    "        wadv=1,\n",
    "        wcon=50,\n",
    "        wenc=1,\n",
    "        lr=0.0002,\n",
    "        beta1=0.5,\n",
    "        beta2=0.999,\n",
    "    )\n",
    "    # max_epochs = 100\n",
    "    # callbacks = [EarlyStopping(monitor=\"image_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"PaDiM\":\n",
    "    model = Padim(\n",
    "        backbone=BACKBONE,\n",
    "        layers=layers[-4:-1],\n",
    "        pre_processor=pre_processor,\n",
    "        n_features=100,\n",
    "        pre_trained=True,\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "elif MODEL_NAME == \"PatchCore\":\n",
    "    model = Patchcore(\n",
    "        backbone=BACKBONE,\n",
    "        layers=layers[-3:-1],\n",
    "        pre_processor=pre_processor,\n",
    "        pre_trained=True,\n",
    "        coreset_sampling_ratio=0.1,\n",
    "        num_neighbors=9,\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "elif MODEL_NAME == \"Reverse Distillation\":\n",
    "    model = ReverseDistillation(\n",
    "        backbone=BACKBONE,\n",
    "        layers=layers[-4:-1],\n",
    "        pre_processor=pre_processor,\n",
    "        anomaly_map_mode=AnomalyMapGenerationMode.ADD,\n",
    "        pre_trained=True,\n",
    "    )\n",
    "    # max_epochs = 200\n",
    "    # callbacks = [EarlyStopping(monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"STFPM\":\n",
    "    model = Stfpm(\n",
    "        backbone=BACKBONE,\n",
    "        layers=layers[-4:-1],\n",
    "        pre_processor=pre_processor,\n",
    "    )\n",
    "    # max_epochs = 100\n",
    "    # callbacks = [EarlyStopping(patience=5, monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"SuperSimpleNet\":\n",
    "    model = Supersimplenet(\n",
    "        backbone=BACKBONE,\n",
    "        layers=layers[-3:-1],\n",
    "        pre_processor=pre_processor,\n",
    "        perlin_threshold = 0.2,\n",
    "        supervised=False,\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "elif MODEL_NAME == \"U-Flow\":\n",
    "    model = Uflow(\n",
    "        backbone=BACKBONE,\n",
    "        # pre_processor=pre_processor,\n",
    "        flow_steps=4,\n",
    "        affine_clamp=2.0,\n",
    "        affine_subnet_channels_ratio=1.0,\n",
    "        permute_soft=False,\n",
    "    )\n",
    "    # max_epochs = 200\n",
    "    # callbacks = [EarlyStopping(patience=20, monitor=\"pixel_AUROC\", mode=\"max\")]\n",
    "elif MODEL_NAME == \"VLM-AD\":\n",
    "    model = VlmAd(\n",
    "        model=ModelName.LLAMA_OLLAMA,\n",
    "        api_key=None,\n",
    "        k_shot=0,\n",
    "    )\n",
    "    # max_epochs = 1\n",
    "elif MODEL_NAME == \"WinCLIP\":\n",
    "    model = WinClip(\n",
    "        # pre_processor=pre_processor,\n",
    "        class_name=\"transistor\",\n",
    "        k_shot=0,\n",
    "        scales=(2, 3),\n",
    "        few_shot_source=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62effd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if MODEL_NAME in [\"SuperSimpleNet\", \"VLM-AD\", \"WinCLIP\"]:\n",
    "    # マスク付き\n",
    "    datamodule = Folder(\n",
    "        name=\"custom_anomaly\",\n",
    "        root=DATASET_PATH_ANOMALY,\n",
    "        normal_dir=Path(\"train\") / \"good\",\n",
    "        abnormal_dir=Path(\"test\") / \"broken_large\",\n",
    "        normal_test_dir=Path(\"test\") / \"good\",\n",
    "        mask_dir=Path(\"ground_truth\") / \"broken_large\",\n",
    "        val_split_mode=ValSplitMode.FROM_TEST,\n",
    "        val_split_ratio=0.2,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        num_workers=1,\n",
    "    )\n",
    "else:\n",
    "    datamodule = Folder(\n",
    "        name=\"custom\",\n",
    "        root=DATASET_PATH,\n",
    "        normal_dir=\"train\",\n",
    "        normal_test_dir=\"test\",\n",
    "        val_split_mode=ValSplitMode.FROM_TRAIN,\n",
    "        # 検証データを入れるとスコアが1か0になるため、検証はしない\n",
    "        # ratioを0にするとデフォルト値で分割されるため、非常に小さい値を設定\n",
    "        val_split_ratio=0.0001,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        num_workers=1,\n",
    "    )\n",
    "datamodule.setup()\n",
    "\n",
    "print(len(datamodule.train_data))\n",
    "print(len(datamodule.val_data))\n",
    "print(len(datamodule.test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 学習 -----\n",
    "engine = Engine(\n",
    "    # callbacks=callbacks,\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")\n",
    "engine.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8448f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(prediction, key):\n",
    "    if not hasattr(prediction, key):\n",
    "        return None\n",
    "    \n",
    "    val = getattr(prediction, key)\n",
    "\n",
    "    # list or tuple\n",
    "    if isinstance(val, (list, tuple)):\n",
    "        return val[0] if len(val) > 0 else None\n",
    "    \n",
    "    # PyTorch Tensor\n",
    "    if isinstance(val, torch.Tensor):\n",
    "        if val.numel() == 0:\n",
    "            return None\n",
    "        if val.numel() == 1:\n",
    "            return val.item()\n",
    "        return val[0] if val.dim() > 0 else val.item()\n",
    "    \n",
    "    # NumPy ndarray\n",
    "    if isinstance(val, np.ndarray):\n",
    "        if val.size == 0:\n",
    "            return None\n",
    "        if val.size == 1:\n",
    "            return val.item()\n",
    "        return val.flat[0]  # flat iteratorで最初の要素\n",
    "    \n",
    "    # それ以外（int, float, etc.）\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # trainデータのスコア\n",
    "    train_predictions = engine.predict(\n",
    "        model=model, dataloaders=datamodule.train_dataloader()\n",
    "    )\n",
    "    train_scores = [get_item(prediction, \"pred_score\") for prediction in train_predictions]\n",
    "    # 閾値（99.7％）\n",
    "    threshold = np.mean(train_scores) + 3 * np.std(train_scores)\n",
    "    # # 四分位範囲×1.5の場合\n",
    "    # threshold = np.percentile(train_scores, 75) + 1.5 * (\n",
    "    #     np.percentile(train_scores, 75) - np.percentile(train_scores, 25)\n",
    "    # )\n",
    "except Exception as e:\n",
    "    print(f\"exception: {e}\")\n",
    "    threshold = 0\n",
    "print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = engine.predict(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ff0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(predictions), ncols=2, figsize=(8, 6))\n",
    "fig.suptitle(f\"{MODEL_NAME}[{BACKBONE}]\", x=0.2)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.0, left=0, right=0.3)\n",
    "\n",
    "\n",
    "def set_ax_style(ax, image):\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    if image is not None:\n",
    "        ax.imshow(image)\n",
    "\n",
    "\n",
    "# TODO\n",
    "if predictions[0].anomaly_map is not None:\n",
    "    # マップの最小値、最大値、範囲\n",
    "    map_min = min(\n",
    "        prediction.anomaly_map[0].min().cpu().numpy()\n",
    "        for prediction in predictions\n",
    "    )\n",
    "    map_max = max(\n",
    "        prediction.anomaly_map[0].max().cpu().numpy()\n",
    "        for prediction in predictions\n",
    "    )\n",
    "    map_ptp = map_max - map_min\n",
    "\n",
    "    def superimpose_anomaly_map_g(\n",
    "        anomaly_map: np.ndarray,\n",
    "        image: np.ndarray,\n",
    "        alpha: float = 0.4,\n",
    "        gamma: int = 0,\n",
    "    ) -> np.ndarray:\n",
    "        nomalized_map = (((anomaly_map - map_min) / map_ptp) * 255).astype(\n",
    "            np.uint8\n",
    "        )\n",
    "        color_map = cv2.applyColorMap(nomalized_map, cv2.COLORMAP_JET)\n",
    "        rgb_color_map = cv2.cvtColor(color_map, cv2.COLOR_BGR2RGB)\n",
    "        height, width = rgb_color_map.shape[:2]\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        return cv2.addWeighted(rgb_color_map, alpha, image, (1 - alpha), gamma)\n",
    "\n",
    "else:\n",
    "\n",
    "    def superimpose_anomaly_map_g(\n",
    "        anomaly_map: np.ndarray,\n",
    "        image: np.ndarray,\n",
    "        alpha: float = 0.4,\n",
    "        gamma: int = 0,\n",
    "    ) -> np.ndarray:\n",
    "        return None\n",
    "\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "\n",
    "    image_path = get_item(prediction, \"image_path\")\n",
    "    image_size = prediction.image.shape[-2:]\n",
    "    image = np.array(Image.open(image_path).resize(image_size))\n",
    "    set_ax_style(ax[i, 0], image)\n",
    "    pred_score = get_item(prediction, \"pred_score\")\n",
    "\n",
    "    if pred_score is None:\n",
    "        pred_score = 0.0\n",
    "\n",
    "    if get_item(prediction, \"gt_mask\") is not None:\n",
    "        # マスクがある場合はラベルから\n",
    "        pred_labels = (\n",
    "            \"Anomaly\" if get_item(prediction, \"pred_label\") else \"Normal\"\n",
    "        )\n",
    "    else:\n",
    "        # 閾値で判定\n",
    "        pred_labels = \"Anomaly\" if pred_score > threshold else \"Normal\"\n",
    "    ax[i, 0].set_title(\n",
    "        f\"[{Path(image_path).name}] Score: {pred_score:.2f} [{pred_labels}]\",\n",
    "        loc=\"left\",\n",
    "    )\n",
    "\n",
    "    anomaly_map = get_item(prediction, \"anomaly_map\")\n",
    "    if anomaly_map is None:\n",
    "        set_ax_style(ax[i, 1], anomaly_map)\n",
    "        continue\n",
    "    anomaly_map = anomaly_map.cpu().numpy().squeeze()\n",
    "\n",
    "    heat_map = superimpose_anomaly_map_g(anomaly_map=anomaly_map, image=image)\n",
    "    set_ax_style(ax[i, 1], heat_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
